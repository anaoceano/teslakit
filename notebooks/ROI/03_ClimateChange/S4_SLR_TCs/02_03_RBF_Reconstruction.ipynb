{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "... ***CURRENTLY UNDER DEVELOPMENT*** ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBFs reconstruction and validation of historical and synthetic data\n",
    "\n",
    "inputs required: \n",
    "  * Historical offshore waves (for plotting)\n",
    "  * Synthetic offshore waves - emulator output climate change\n",
    "  * Sea and swell SWAN simulated cases from ***Notebook 02_02***\n",
    "\n",
    "in this notebook:\n",
    "  * RBF reconstruction simulated storms\n",
    "  * Validation: AWAC measurement - Synthetic and historical histograms - Extremes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# common\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# DEV: override installed teslakit\n",
    "import sys\n",
    "sys.path.insert(0, op.join(os.path.abspath(''), '..', '..', '..', '..'))\n",
    "\n",
    "# teslakit\n",
    "from teslakit.database import Database\n",
    "from teslakit.rbf import RBF_Reconstruction, RBF_Validation\n",
    "from teslakit.waves import Aggregate_WavesFamilies, AWL\n",
    "from teslakit.climate_emulator import Climate_Emulator\n",
    "\n",
    "from teslakit.plotting.extremes import Plot_ReturnPeriodValidation\n",
    "from teslakit.plotting.waves import Plot_Waves_Histogram_FitSim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Database and Site parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Teslakit database\n",
    "\n",
    "p_data = r'/Users/albacid/Projects/TeslaKit_projects'\n",
    "db = Database(p_data)\n",
    "\n",
    "# offshore\n",
    "db = Database(p_data)\n",
    "db.SetSite('ROI')\n",
    "\n",
    "# climate change - S4\n",
    "db_S4 = Database(p_data)\n",
    "db_S4.SetSite('ROI_CC_S4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sea and Swells data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def split_sea_swells(WVS):\n",
    "    '''\n",
    "    splits WVS dataframe data into sea waves & swell waves dataframes\n",
    "    \n",
    "    requires WVS to contain variables with these names:\n",
    "        'sea_Hs', 'sea_Tp', 'sea_Dir'\n",
    "        'swell_1_Hs', 'swell_1_Tp', 'swell_1_Dir'\n",
    "        'swell_2_Hs', 'swell_2_Tp', 'swell_2_Dir'\n",
    "        ...\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # store n_sim if found in WVS dataset\n",
    "    vns_extra = []\n",
    "    if 'n_sim' in list(WVS.columns):\n",
    "        vns_extra.append('n_sim') \n",
    "\n",
    "    \n",
    "    # Prepare SEA waves\n",
    "    vns_sea = ['sea_Hs', 'sea_Tp', 'sea_Dir'] + vns_extra\n",
    "    \n",
    "    wvs_sea = WVS[vns_sea]\n",
    "    wvs_sea.dropna(inplace=True)  # clean nans\n",
    "    wvs_sea.rename(columns={\"sea_Hs\":\"hs\", \"sea_Tp\":\"tp\", \"sea_Dir\": \"dir\"}, inplace=True)  # rename columns\n",
    "    wvs_sea = wvs_sea[wvs_sea[\"dir\"]<=360]  # filter data\n",
    "    \n",
    "    # Prepare SWELL_1 waves\n",
    "    vns_swell_1 = ['swell_1_Hs', 'swell_1_Tp', 'swell_1_Dir'] + vns_extra\n",
    "\n",
    "    wvs_swell_1 = WVS[vns_swell_1]\n",
    "    wvs_swell_1.dropna(inplace=True)\n",
    "    wvs_swell_1.rename(columns={\"swell_1_Hs\":\"hs\", \"swell_1_Tp\":\"tp\", \"swell_1_Dir\": \"dir\"}, inplace=True)\n",
    "    wvs_swell_1 = wvs_swell_1[wvs_swell_1[\"dir\"]<=360]  \n",
    "\n",
    "    # Prepare SWELL_2 waves\n",
    "    vns_swell_2 = ['swell_2_Hs', 'swell_2_Tp', 'swell_2_Dir'] + vns_extra\n",
    "\n",
    "    wvs_swell_2 = WVS[vns_swell_2]\n",
    "    wvs_swell_2.dropna(inplace=True)\n",
    "    wvs_swell_2.rename(columns={\"swell_2_Hs\":\"hs\", \"swell_2_Tp\":\"tp\", \"swell_2_Dir\": \"dir\"}, inplace=True)\n",
    "    wvs_swell_2 = wvs_swell_2[wvs_swell_2[\"dir\"]<=360]  \n",
    "\n",
    "\n",
    "    # join swell data\n",
    "    wvs_swell = pd.concat([wvs_swell_1, wvs_swell_2], ignore_index=True)\n",
    "    \n",
    "    return wvs_sea, wvs_swell\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Waves data\n",
    "\n",
    "# Climate Emulator DWTs-WVS simulations\n",
    "WVS_sim = db_S4.Load_CE_AllSims()\n",
    "\n",
    "# --------------------------------------\n",
    "# split waves data by family\n",
    "\n",
    "# Prepare Simulated waves: split sea, swells\n",
    "wvs_sea_sim, wvs_swl_sim = split_sea_swells(WVS_sim)\n",
    "db_S4.Save_NEARSHORE_SIM_sea(wvs_sea_sim)\n",
    "db_S4.Save_NEARSHORE_SIM_swell(wvs_swl_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files: dataset, subset (MDA classification), and target (SWAN simulations output)\n",
    "\n",
    "# sea \n",
    "wvs_sea_dataset_sim = db.Load_NEARSHORE_SIM_sea()\n",
    "wvs_sea_dataset_sim_CC = db_S4.Load_NEARSHORE_SIM_sea()\n",
    "wvs_sea_dataset_hist = db.Load_NEARSHORE_HIST_sea()\n",
    "wvs_sea_subset = db.Load_NEARSHORE_MDA_sea()\n",
    "wvs_sea_target = db.Load_NEARSHORE_TARGET_sea() # SWAN simulation outputs\n",
    "\n",
    "# swells \n",
    "wvs_swell_dataset_sim = db.Load_NEARSHORE_SIM_swell()\n",
    "wvs_swell_dataset_sim_CC = db_S4.Load_NEARSHORE_SIM_swell()\n",
    "wvs_swell_dataset_hist = db.Load_NEARSHORE_HIST_swell()\n",
    "wvs_swell_subset = db.Load_NEARSHORE_MDA_swell()\n",
    "wvs_swell_target = db.Load_NEARSHORE_TARGET_swell() # SWAN simulation outputs\n",
    "\n",
    "# keep datasets n_sim column\n",
    "sea_n_sim = wvs_sea_dataset_sim['n_sim']\n",
    "swl_n_sim = wvs_swell_dataset_sim['n_sim']\n",
    "sea_n_sim_CC = wvs_sea_dataset_sim_CC['n_sim']\n",
    "swl_n_sim_CC = wvs_swell_dataset_sim_CC['n_sim']\n",
    "\n",
    "\n",
    "# remove nans (if any) from subset and target\n",
    "def fix_target_nans(subset, target):\n",
    "    'remove NaN data indexes from subset and target. RBF does not handle NaNs'\n",
    "    \n",
    "    r_nan = target.isnull().any(axis=1)  # find any row with nans\n",
    "\n",
    "    if r_nan.any():\n",
    "        # log\n",
    "        print('remove nan data found at target:')\n",
    "        print(target[r_nan])\n",
    "        \n",
    "        # clean data\n",
    "        target = target[~r_nan]\n",
    "        subset = subset[~r_nan]\n",
    "        \n",
    "    return subset, target\n",
    "\n",
    "wvs_sea_subset, wvs_sea_target = fix_target_nans(wvs_sea_subset, wvs_sea_target)\n",
    "wvs_swell_subset, wvs_swell_target = fix_target_nans(wvs_swell_subset, wvs_swell_target)\n",
    "\n",
    "\n",
    "# ensure dataset and subset have same variables and column order\n",
    "vns_ds = ['hs', 'tp', 'dir']\n",
    "\n",
    "wvs_sea_dataset_sim = wvs_sea_dataset_sim[vns_ds].values\n",
    "wvs_sea_dataset_hist = wvs_sea_dataset_hist[vns_ds].values\n",
    "wvs_sea_subset = wvs_sea_subset[vns_ds].values\n",
    "\n",
    "wvs_swell_dataset_sim = wvs_swell_dataset_sim[vns_ds].values\n",
    "wvs_swell_dataset_hist = wvs_swell_dataset_hist[vns_ds].values\n",
    "wvs_swell_subset = wvs_swell_subset[vns_ds].values\n",
    "\n",
    "\n",
    "# select target variables\n",
    "vns_tgt = ['Hsig', 'TPsmoo', 'Dir']\n",
    "\n",
    "wvs_sea_target = wvs_sea_target[vns_tgt].values\n",
    "wvs_swell_target = wvs_swell_target[vns_tgt].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF settings\n",
    "\n",
    "# subset - scalar / directional indexes\n",
    "ix_scalar_subset = [0,1]      # scalar (hs, tp)\n",
    "ix_directional_subset = [2]   # directional (dir)\n",
    "\n",
    "# target - scalar / directional indexes\n",
    "ix_scalar_target = [0,1]      # scalar (Hsig, Tpsmoo, Dir)\n",
    "ix_directional_target = [2]   # directional (Dir)\n",
    "\n",
    "\n",
    "# RBF wrappers \n",
    "def RBF_Reconstruction_sea(dataset_input):\n",
    "    \n",
    "    return RBF_Reconstruction(\n",
    "    wvs_sea_subset, ix_scalar_subset, ix_directional_subset,\n",
    "    wvs_sea_target, ix_scalar_target, ix_directional_target,\n",
    "    dataset_input)\n",
    "\n",
    "def RBF_Reconstruction_swell(dataset_input):\n",
    "    \n",
    "    return RBF_Reconstruction(\n",
    "    wvs_swell_subset, ix_scalar_subset, ix_directional_subset,\n",
    "    wvs_swell_target, ix_scalar_target, ix_directional_target,\n",
    "    dataset_input)\n",
    "\n",
    "def RBF_Reconstruction_families(data):\n",
    "   \n",
    "    # sea\n",
    "    vs = ['sea_Hs', 'sea_Tp', 'sea_Dir']\n",
    "    data_sea = data[vs].to_dataframe().dropna()\n",
    "    data_sea.drop(data_sea[(data_sea['sea_Dir'] >= 360)].index, inplace=True)  # fix sea_Dir >> 360 bug    \n",
    "    rec_sea = RBF_Reconstruction_sea(data_sea.values)\n",
    "    rec_sea = pd.DataFrame(data=rec_sea, columns=vs, index=data_sea.index)\n",
    "\n",
    "    # swell 1\n",
    "    vs = ['swell_1_Hs', 'swell_1_Tp', 'swell_1_Dir']\n",
    "    data_swl_1 = data[vs].to_dataframe().dropna()\n",
    "    rec_swl_1 = RBF_Reconstruction_swell(data_swl_1.values)\n",
    "    rec_swl_1 = pd.DataFrame(data=rec_swl_1, columns=vs, index=data_swl_1.index)\n",
    "\n",
    "    # swell 2\n",
    "    vs = ['swell_2_Hs', 'swell_2_Tp', 'swell_2_Dir']\n",
    "    data_swl_2 = data[vs].to_dataframe().dropna()\n",
    "    rec_swl_2 = RBF_Reconstruction_swell(data_swl_2.values)\n",
    "    rec_swl_2 = pd.DataFrame(data=rec_swl_2, columns=vs, index=data_swl_2.index)\n",
    "    \n",
    "    # join nearshore reconstructed data and parse to xarray.Dataset\n",
    "    rec_waves = pd.concat([rec_sea, rec_swl_1, rec_swl_2], axis=1)\n",
    "\n",
    "    return xr.Dataset.from_dataframe(rec_waves)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RBF Reconstruct SEA Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# RBF Interpolation\n",
    "\n",
    "# TODO: activate + sca_val plot\n",
    "\n",
    "# Simulated SEA waves\n",
    "sea_rec_sim = RBF_Reconstruction_sea(wvs_sea_dataset_sim)\n",
    "df_sea_recon_sim = pd.DataFrame(data=sea_rec_sim, columns=vns_tgt)\n",
    "df_sea_recon_sim['n_sim'] = sea_n_sim  # keep n_sim value\n",
    "\n",
    "\n",
    "# Historical SEA waves\n",
    "sea_rec_hist = RBF_Reconstruction_sea(wvs_sea_dataset_hist)\n",
    "df_sea_recon_hist = pd.DataFrame(data=sea_rec_hist, columns=vns_tgt)\n",
    "\n",
    "\n",
    "# store data\n",
    "db_s4.Save_NEARSHORE_RECONSTRUCTION_SIM_sea(df_sea_recon_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RBF Reconstruct SWELL Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# RBF Interpolation\n",
    "\n",
    "# TODO: activate + sca_val plot\n",
    "\n",
    "# Simulated SWELL waves\n",
    "#swl_rec_sim = RBF_Reconstruction_swell(wvs_swell_dataset_sim)\n",
    "#df_swl_recon_sim = pd.DataFrame(data=swl_rec_sim, columns=vns_tgt)\n",
    "#df_swl_recon_sim['n_sim'] = swl_n_sim  # keep n_sim value\n",
    "\n",
    "\n",
    "# Historical SWELL waves\n",
    "#swl_rec_hist = RBF_Reconstruction_swell(wvs_swell_dataset_hist)\n",
    "#df_swl_recon_hist = pd.DataFrame(data=swl_rec_hist, columns=vns_tgt)\n",
    "\n",
    "\n",
    "# store data\n",
    "#db.Save_NEARSHORE_RECONSTRUCTION_SIM_swell(df_swl_recon_sim)\n",
    "#db.Save_NEARSHORE_RECONSTRUCTION_HIST_swell(df_swl_recon_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load historical and simulated offshore waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load climate emulator historical waves (storms)\n",
    "WVS_hist = db.Load_HIST_Complete_storms()\n",
    "WVS_hist['AWL'] = AWL(WVS_hist.Hs, WVS_hist.Tp) # calculate AWL\n",
    "\n",
    "\n",
    "# Load cliamte emulator simulation waves (storms)\n",
    "n_sims_DWTs = 10\n",
    "l_WVS_sim = db.Load_SIM_Complete_storms(n_sims_DWTs)\n",
    "for WVS_sim in l_WVS_sim: WVS_sim['AWL'] = AWL(WVS_sim.Hs, WVS_sim.Tp) # calculate AWL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare historical and simulations annual maxima (for storms)\n",
    "\n",
    "vns = ['Hs', 'Tp', 'AWL']\n",
    "for vn in vns:\n",
    "\n",
    "    # calculate Annual Maxima values for historical and simulated data\n",
    "    hist_A = WVS_hist[vn].groupby('time.year').max(dim='time')\n",
    "    sim_A = xr.concat([x[vn].groupby('time.year').max(dim='time') for x in l_WVS_sim], 'n_sim')\n",
    "\n",
    "    # Return Period historical vs. simulations\n",
    "    Plot_ReturnPeriodValidation(hist_A, sim_A);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RBF Reconstruct Historical storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reconstruct waves by families\n",
    "WVS_HIST_rec = RBF_Reconstruction_families(WVS_hist)\n",
    "\n",
    "# aggregate nearshore variables\n",
    "WVS_a = Aggregate_WavesFamilies(WVS_HIST_rec)\n",
    "WVS_HIST_rec = xr.merge([WVS_HIST_rec, WVS_a])\n",
    "\n",
    "# calculate AWL\n",
    "WVS_HIST_rec['AWL'] = AWL(WVS_HIST_rec.Hs, WVS_HIST_rec.Tp)\n",
    "\n",
    "    \n",
    "# store historical storms waves reconstruction\n",
    "db.Save_NEARSHORE_RECONSTRUCTION_HIST_storms(WVS_HIST_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RBF Reconstruct Simulation storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "l_sims_rec = []\n",
    "for data in l_WVS_sim:\n",
    "    \n",
    "    # Reconstruct waves by families\n",
    "    WVS_SIM_rec = RBF_Reconstruction_families(data)\n",
    "    \n",
    "    # aggregate nearshore variables\n",
    "    WVS_a = Aggregate_WavesFamilies(WVS_SIM_rec)\n",
    "    WVS_SIM_rec = xr.merge([WVS_SIM_rec, WVS_a])\n",
    "    \n",
    "    # calculate AWL\n",
    "    WVS_SIM_rec['AWL'] = AWL(WVS_SIM_rec.Hs, WVS_SIM_rec.Tp)\n",
    "\n",
    "    l_sims_rec.append(WVS_SIM_rec)\n",
    "    \n",
    "    \n",
    "# store simulations storms waves reconstruction\n",
    "db.Save_NEARSHORE_RECONSTRUCTION_SIM_storms(l_sims_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology Validation: Buoy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: validate with AWAC + plot\n",
    "# TODO 02b_Validation AWAC.ipynb mejor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Methodology Validation: Historical - Simulation Waves Families Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s, WVS_sim_rec in enumerate(l_sims_rec):\n",
    "    \n",
    "    print('SIM n. {0}'.format(s))\n",
    "    Plot_Waves_Histogram_FitSim(WVS_HIST_rec, WVS_sim_rec);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Methodology Validation: Historical - Simulation Annual Maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare historical and simulations reconstruction vars. annual maxima\n",
    "\n",
    "vns = ['Hs', 'Tp', 'AWL']\n",
    "for vn in vns:\n",
    "\n",
    "    # calculate Annual Maxima values for historical and simulated data\n",
    "    hist_A = WVS_HIST_rec[vn].groupby('time.year').max(dim='time')\n",
    "    sim_A = xr.concat([x[vn].groupby('time.year').max(dim='time') for x in l_sims_rec], 'n_sim')\n",
    "\n",
    "    # Return Period historical vs. simulations\n",
    "    Plot_ReturnPeriodValidation(hist_A, sim_A);\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
